import asyncio
from typing import List, Dict, Any
import os
from datetime import datetime, timedelta
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
import pickle
import json
import hashlib
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
import google.generativeai as genai

class SubAgent:
    """ì„œë¸Œ ì—ì´ì „íŠ¸ (3ê°œ ìš´ì˜)"""
    
    def __init__(self, agent_id: str, config: Dict):
        self.agent_id = agent_id
        self.config = config
        self.name = f"SubAgent-{agent_id}"
        
        # ê° ì„œë¸Œ ì—ì´ì „íŠ¸ë³„ ë‹¤ë¥¸ Gmail ê³„ì •
        self.email = config[f"AGENT_{agent_id}_EMAIL"]
        self.password = config[f"AGENT_{agent_id}_PASSWORD"]
        self.gemini_key = config[f"AGENT_{agent_id}_GEMINI_KEY"]
        
        # ì „ë¬¸ ë¶„ì•¼ ì„¤ì •
        self.specialty = config["AGENT_SPECIALTIES"][agent_id]
    
    async def collect_and_analyze(self) -> Dict:
        """ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„"""
        
        print(f"\nğŸ¤– {self.name} ì‘ì—… ì‹œì‘ (ì „ë¬¸: {self.specialty['focus']})")
        
        try:
            # 1. ì „ë¬¸ ë¶„ì•¼ì— ë§ëŠ” ë°ì´í„° ìˆ˜ì§‘
            data = await self.collect_specialized_data()
            
            # 2. Geminië¡œ ë¶„ì„
            analysis = await self.analyze_with_gemini(data)
            
            # 3. ë¦¬í¬íŠ¸ ìƒì„±
            report = self.create_agent_report(data, analysis)
            
            # 4. Gmailë¡œ ë©”ì¸ ì—ì´ì „íŠ¸ì—ê²Œ ì „ì†¡
            await self.send_to_main_agent(report)
            
            return report
            
        except Exception as e:
            print(f"âŒ {self.name} ì˜¤ë¥˜: {e}")
            return {"error": str(e), "agent_id": self.agent_id}
    
    async def collect_specialized_data(self) -> Dict:
        """ì „ë¬¸ ë¶„ì•¼ë³„ ë°ì´í„° ìˆ˜ì§‘"""
        
        from scrapper.collectors import DataCollector
        
        # ì»¤ìŠ¤í…€ ì„¤ì •
        custom_config = self.config.copy()
        
        # ì „ë¬¸ ë¶„ì•¼ì— ë§ê²Œ í•„í„°ë§
        if self.agent_id == "A":
            # AI/ML ì¤‘ì‹¬
            custom_config["REDDIT_CONFIG"]["subreddits"] = [
                "MachineLearning", "artificial", "LocalLLaMA", "singularity", "OpenAI"
            ]
            custom_config["FILTER_KEYWORDS"]["must_have_any"] = self.specialty["keywords"]
            
        elif self.agent_id == "B":
            # Frontend/CSS ì¤‘ì‹¬
            custom_config["REDDIT_CONFIG"]["subreddits"] = [
                "css", "webdev", "Frontend", "web_design", "reactjs", "vuejs"
            ]
            custom_config["FILTER_KEYWORDS"]["must_have_any"] = self.specialty["keywords"]
            
        elif self.agent_id == "C":
            # Backend/DevOps ì¤‘ì‹¬
            custom_config["REDDIT_CONFIG"]["subreddits"] = [
                "programming", "devops", "golang", "rust", "node", "kubernetes"
            ]
            custom_config["FILTER_KEYWORDS"]["must_have_any"] = self.specialty["keywords"]
        
        collector = DataCollector(custom_config)
        return await collector.collect_all()
    
    async def analyze_with_gemini(self, data: Dict) -> Dict:
        """Geminië¡œ ì „ë¬¸ ë¶„ì„"""
        
        genai.configure(api_key=self.gemini_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # ì „ë¬¸ ë¶„ì•¼ë³„ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¹ì‹ ì€ {self.specialty['focus']} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        
        ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
        
        1. ê°€ì¥ ì¤‘ìš”í•œ íŠ¸ë Œë“œ 3ê°œ
        2. ì£¼ëª©í•  ë§Œí•œ ìƒˆë¡œìš´ ë„êµ¬/ê¸°ìˆ 
        3. ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ê³¼ ê°ì •
        4. í–¥í›„ ì˜ˆì¸¡
        5. í•œêµ­ ê°œë°œìë¥¼ ìœ„í•œ êµ¬ì²´ì  ì¡°ì–¸
        
        ë°ì´í„° ìš”ì•½:
        - Reddit í¬ìŠ¤íŠ¸: {len(data.get('reddit', []))}ê°œ
        - HackerNews: {len(data.get('hackernews', []))}ê°œ
        - GitHub: {len(data.get('github', []))}ê°œ
        - RSS: {len(data.get('rss', []))}ê°œ
        
        ì£¼ìš” ë‚´ìš©:
        {self._extract_top_items(data)}
        
        í•œêµ­ì–´ë¡œ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = model.generate_content(prompt)
            
            return {
                "raw_analysis": response.text,
                "timestamp": datetime.now().isoformat(),
                "agent_id": self.agent_id,
                "specialty": self.specialty['focus'],
                "data_stats": {
                    "reddit": len(data.get('reddit', [])),
                    "hackernews": len(data.get('hackernews', [])),
                    "github": len(data.get('github', [])),
                    "rss": len(data.get('rss', []))
                }
            }
            
        except Exception as e:
            print(f"âŒ {self.name} Gemini ì˜¤ë¥˜: {e}")
            return {"error": str(e), "agent_id": self.agent_id}
    
    def _extract_top_items(self, data: Dict) -> str:
        """ìƒìœ„ ì•„ì´í…œ ì¶”ì¶œ"""
        
        items = []
        
        # Reddit Top 5
        for item in data.get('reddit', [])[:5]:
            items.append(f"Reddit: {item.get('title')} (ì ìˆ˜: {item.get('score')})")
        
        # HackerNews Top 5
        for item in data.get('hackernews', [])[:5]:
            items.append(f"HN: {item.get('title')} (ì ìˆ˜: {item.get('score')})")
        
        # GitHub Top 3
        for item in data.get('github', [])[:3]:
            items.append(f"GitHub: {item.get('name')} - {item.get('description')[:100]}")
        
        return "\n".join(items)
    
    def create_agent_report(self, data: Dict, analysis: Dict) -> Dict:
        """ì—ì´ì „íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        # ì¤‘ë³µ ì²´í¬ìš© í•´ì‹œ
        content_hash = hashlib.md5(
            json.dumps(data, sort_keys=True).encode()
        ).hexdigest()[:8]
        
        report = {
            "agent_id": self.agent_id,
            "agent_name": self.name,
            "specialty": self.specialty['focus'],
            "timestamp": datetime.now().isoformat(),
            "content_hash": content_hash,
            "data_summary": {
                "total_items": sum(
                    len(v) for v in data.values() if isinstance(v, list)
                ),
                "sources": list(data.keys())
            },
            "analysis": analysis,
            "top_findings": self._extract_top_findings(data),
            "raw_data": data
        }
        
        return report
    
    def _extract_top_findings(self, data: Dict) -> List[Dict]:
        """ì£¼ìš” ë°œê²¬ ì‚¬í•­ ì¶”ì¶œ"""
        
        findings = []
        
        # Reddit ìµœê³  ì¸ê¸°
        reddit_posts = data.get('reddit', [])
        if reddit_posts:
            top_reddit = max(reddit_posts, key=lambda x: x.get('score', 0))
            findings.append({
                "type": "reddit_top",
                "title": top_reddit.get('title'),
                "score": top_reddit.get('score'),
                "url": top_reddit.get('url')
            })
        
        # GitHub ìµœê³  ìŠ¤íƒ€
        github_repos = data.get('github', [])
        if github_repos:
            top_repo = max(github_repos, key=lambda x: x.get('stars', 0))
            findings.append({
                "type": "github_top",
                "name": top_repo.get('name'),
                "stars": top_repo.get('stars'),
                "url": top_repo.get('url')
            })
        
        return findings
    
    async def send_to_main_agent(self, report: Dict):
        """Gmailë¡œ ë©”ì¸ ì—ì´ì „íŠ¸ì—ê²Œ ì „ì†¡"""
        
        try:
            # ì´ë©”ì¼ ìƒì„±
            msg = MIMEMultipart()
            msg['From'] = self.email
            msg['To'] = self.config["MAIN_AGENT_EMAIL"]
            msg['Subject'] = f"[AI-TREND-{self.agent_id}] {self.specialty['focus']} ë¶„ì„ ë¦¬í¬íŠ¸"
            
            # HTML ë³¸ë¬¸
            html_body = self._create_email_html(report)
            msg.attach(MIMEText(html_body, 'html'))
            
            # JSON ì²¨ë¶€íŒŒì¼
            json_attachment = MIMEApplication(
                json.dumps(report, ensure_ascii=False, indent=2)
            )
            json_attachment.add_header(
                'Content-Disposition',
                f'attachment; filename="{self.name}_report_{datetime.now().strftime("%Y%m%d")}.json"'
            )
            msg.attach(json_attachment)
            
            # ì „ì†¡
            with smtplib.SMTP('smtp.gmail.com', 587) as server:
                server.starttls()
                server.login(self.email, self.password)
                server.send_message(msg)
            
            print(f"âœ… {self.name} ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ {self.name} ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def _create_email_html(self, report: Dict) -> str:
        """ì´ë©”ì¼ HTML ìƒì„±"""
        
        return f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; }}
                .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; }}
                .content {{ padding: 20px; }}
                .stats {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; margin: 20px 0; }}
                .stat-card {{ background: #f5f5f5; padding: 15px; border-radius: 8px; text-align: center; }}
                .findings {{ background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 20px 0; }}
                .analysis {{ background: #fff; padding: 20px; border: 1px solid #ddd; border-radius: 8px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ¤– {self.name} ë¦¬í¬íŠ¸</h1>
                <p>ì „ë¬¸ ë¶„ì•¼: {report['specialty']}</p>
                <p>ìˆ˜ì§‘ ì‹œê°„: {report['timestamp']}</p>
            </div>
            
            <div class="content">
                <div class="stats">
                    <div class="stat-card">
                        <h3>Reddit</h3>
                        <p>{report['analysis'].get('data_stats', {}).get('reddit', 0)}</p>
                    </div>
                    <div class="stat-card">
                        <h3>HackerNews</h3>
                        <p>{report['analysis'].get('data_stats', {}).get('hackernews', 0)}</p>
                    </div>
                    <div class="stat-card">
                        <h3>GitHub</h3>
                        <p>{report['analysis'].get('data_stats', {}).get('github', 0)}</p>
                    </div>
                    <div class="stat-card">
                        <h3>RSS</h3>
                        <p>{report['analysis'].get('data_stats', {}).get('rss', 0)}</p>
                    </div>
                </div>
                
                <div class="findings">
                    <h2>ğŸ”¥ ì£¼ìš” ë°œê²¬</h2>
                    {self._format_findings(report.get('top_findings', []))}
                </div>
                
                <div class="analysis">
                    <h2>ğŸ“Š AI ë¶„ì„ ê²°ê³¼</h2>
                    <pre style="white-space: pre-wrap;">{report['analysis'].get('raw_analysis', 'N/A')}</pre>
                </div>
            </div>
        </body>
        </html>
        """
    
    def _format_findings(self, findings: List[Dict]) -> str:
        """ì£¼ìš” ë°œê²¬ í¬ë§·"""
        
        html = "<ul>"
        for finding in findings:
            if finding['type'] == 'reddit_top':
                html += f"<li>Reddit ìµœê³  ì¸ê¸°: {finding['title']} ({finding['score']} points)</li>"
            elif finding['type'] == 'github_top':
                html += f"<li>GitHub ìµœê³  ìŠ¤íƒ€: {finding['name']} (â­ {finding['stars']})</li>"
        html += "</ul>"
        return html


class MainAgent:
    """ë©”ì¸ ì—ì´ì „íŠ¸ - ì¢…í•© ë¶„ì„"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.email = config["MAIN_AGENT_EMAIL"]
        self.gemini_key = config["MAIN_AGENT_GEMINI_KEY"]
        
        # Gmail API ì„¤ì • (ì„ íƒì‚¬í•­)
        self.gmail_service = None
        
        # ì´ì „ ë¶„ì„ ê¸°ë¡ ë¡œë“œ
        self.history = self.load_history()
    
    async def collect_sub_agent_reports(self, direct_reports: List[Dict]) -> List[Dict]:
        """ì„œë¸Œ ì—ì´ì „íŠ¸ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ (ì§ì ‘ ì „ë‹¬)"""
        
        print("\nğŸ‘‘ ë©”ì¸ ì—ì´ì „íŠ¸: ì„œë¸Œ ì—ì´ì „íŠ¸ ë¦¬í¬íŠ¸ ì¢…í•© ì¤‘...")
        
        # ì§ì ‘ ì „ë‹¬ë°›ì€ ë¦¬í¬íŠ¸ ì‚¬ìš©
        return direct_reports
    
    async def analyze_historical_context(self, current_reports: List[Dict]) -> Dict:
        """ê³¼ê±° ë°ì´í„°ì™€ ë¹„êµ ë¶„ì„"""
        
        print("ğŸ“š ê³¼ê±° ë°ì´í„°ì™€ ë¹„êµ ë¶„ì„ ì¤‘...")
        
        context = {
            "trends_evolution": [],
            "recurring_topics": [],
            "new_discoveries": [],
            "sentiment_shift": {}
        }
        
        # ìµœê·¼ 30ì¼ ë°ì´í„°
        recent_history = self.get_recent_history(days=30)
        
        # ì¤‘ë³µ ì œê±°
        seen_hashes = set()
        unique_content = []
        
        for report in current_reports:
            content_hash = report.get('content_hash')
            
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique_content.append(report)
            
            # ê³¼ê±° ë°ì´í„°ì™€ ë¹„êµ
            for past_report in recent_history:
                similarity = self.calculate_similarity(
                    report.get('analysis', {}),
                    past_report.get('analysis', {})
                )
                
                if similarity > 0.7:
                    context["recurring_topics"].append({
                        "topic": report.get('specialty'),
                        "frequency": similarity
                    })
        
        # íŠ¸ë Œë“œ ì§„í™” ë¶„ì„
        context["trends_evolution"] = self.analyze_trend_evolution(
            unique_content, recent_history
        )
        
        return context
    
    def calculate_similarity(self, analysis1: Dict, analysis2: Dict) -> float:
        """ìœ ì‚¬ë„ ê³„ì‚°"""
        
        from difflib import SequenceMatcher
        
        text1 = str(analysis1.get('raw_analysis', ''))
        text2 = str(analysis2.get('raw_analysis', ''))
        
        return SequenceMatcher(None, text1, text2).ratio()
    
    def analyze_trend_evolution(self, current: List, history: List) -> List:
        """íŠ¸ë Œë“œ ì§„í™” ë¶„ì„"""
        
        evolution = []
        topics = {}
        
        for report in current + history:
            specialty = report.get('specialty', 'Unknown')
            if specialty not in topics:
                topics[specialty] = []
            topics[specialty].append(report)
        
        for topic, reports in topics.items():
            if len(reports) > 1:
                reports.sort(key=lambda x: x['timestamp'])
                
                evolution.append({
                    "topic": topic,
                    "trend": "growing" if len(reports) > 3 else "stable",
                    "first_seen": reports[0]['timestamp'],
                    "last_seen": reports[-1]['timestamp'],
                    "frequency": len(reports)
                })
        
        return evolution
    
    async def synthesize_final_report(self, 
                                     sub_reports: List[Dict],
                                     context: Dict) -> Dict:
        """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        
        print("ğŸ¯ ìµœì¢… ì¢…í•© ë¶„ì„ ì¤‘...")
        
        genai.configure(api_key=self.gemini_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # ëª¨ë“  ì„œë¸Œ ì—ì´ì „íŠ¸ ë¶„ì„ ì¢…í•©
        all_analyses = []
        for report in sub_reports:
            if 'analysis' in report and 'raw_analysis' in report['analysis']:
                all_analyses.append({
                    "agent": report['agent_id'],
                    "specialty": report['specialty'],
                    "analysis": report['analysis']['raw_analysis'],
                    "top_findings": report.get('top_findings', [])
                })
        
        prompt = f"""
        ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸°ìˆ  ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        
        3ëª…ì˜ ì „ë¬¸ ë¶„ì„ê°€ê°€ ì œì¶œí•œ ë¦¬í¬íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… í†µí•© ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.
        
        ë¶„ì„ê°€ ë¦¬í¬íŠ¸ë“¤:
        {json.dumps(all_analyses, ensure_ascii=False)[:8000]}
        
        ê³¼ê±° íŠ¸ë Œë“œ ì»¨í…ìŠ¤íŠ¸:
        - ë°˜ë³µ ì£¼ì œ: {len(context.get('recurring_topics', []))}ê°œ
        - íŠ¸ë Œë“œ ì§„í™”: {context.get('trends_evolution', [])}
        
        ë‹¤ìŒì„ í¬í•¨í•œ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”:
        
        1. ğŸ”¥ ì´ë²ˆ ì£¼ ê°€ì¥ ì¤‘ìš”í•œ íŠ¸ë Œë“œ TOP 5
        2. ğŸ†• ìƒˆë¡­ê²Œ ë“±ì¥í•œ ê¸°ìˆ /ë„êµ¬
        3. ğŸ“ˆ ì„±ì¥ ì¤‘ì¸ íŠ¸ë Œë“œ vs ğŸ“‰ í•˜ë½ ì¤‘ì¸ íŠ¸ë Œë“œ
        4. ğŸ”® í–¥í›„ 3ê°œì›” ì˜ˆì¸¡
        5. ğŸ’¡ í•œêµ­ ê°œë°œìë¥¼ ìœ„í•œ êµ¬ì²´ì  ì•¡ì…˜ ì•„ì´í…œ 5ê°œ
        6. âš ï¸ ì£¼ì˜í•´ì•¼ í•  ê¸°ìˆ ì  ë¦¬ìŠ¤í¬
        7. ğŸ¯ ê° ë¶„ì•¼ë³„ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (AI/Frontend/Backend)
        
        êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•˜ì„¸ìš”.
        í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = model.generate_content(prompt)
            
            final_report = {
                "timestamp": datetime.now().isoformat(),
                "sub_agents_count": len(sub_reports),
                "synthesis": response.text,
                "context": context,
                "sub_reports_summary": [
                    {
                        "agent_id": r.get('agent_id'),
                        "specialty": r.get('specialty'),
                        "items_collected": r.get('data_summary', {}).get('total_items', 0)
                    }
                    for r in sub_reports
                ],
                "deduplication_stats": {
                    "total_items": sum(
                        r.get('data_summary', {}).get('total_items', 0)
                        for r in sub_reports
                    ),
                    "unique_items": len(set(
                        r.get('content_hash') for r in sub_reports
                    ))
                }
            }
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self.save_to_history(final_report)
            
            return final_report
            
        except Exception as e:
            print(f"âŒ ìµœì¢… ì¢…í•© ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def load_history(self) -> List[Dict]:
        """ê³¼ê±° ë¶„ì„ ê¸°ë¡ ë¡œë“œ"""
        
        history_file = "outputs/agent_history.json"
        
        if os.path.exists(history_file):
            try:
                with open(history_file, 'r') as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def save_to_history(self, report: Dict):
        """ë¶„ì„ ê¸°ë¡ ì €ì¥"""
        
        history_file = "outputs/agent_history.json"
        os.makedirs("outputs", exist_ok=True)
        
        history = self.load_history()
        history.append(report)
        
        # ìµœê·¼ 90ì¼ì¹˜ë§Œ ìœ ì§€
        cutoff = datetime.now() - timedelta(days=90)
        history = [
            h for h in history
            if datetime.fromisoformat(h['timestamp']) > cutoff
        ]
        
        with open(history_file, 'w') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    
    def get_recent_history(self, days: int = 30) -> List[Dict]:
        """ìµœê·¼ ê¸°ë¡ ì¡°íšŒ"""
        
        cutoff = datetime.now() - timedelta(days=days)
        history = self.load_history()
        
        return [
            h for h in history
            if datetime.fromisoformat(h['timestamp']) > cutoff
        ]


class MultiAgentOrchestrator:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self, config: Dict):
        self.config = config
        
        # ì„œë¸Œ ì—ì´ì „íŠ¸ 3ê°œ ìƒì„±
        self.sub_agents = [
            SubAgent("A", config),
            SubAgent("B", config),
            SubAgent("C", config)
        ]
        
        # ë©”ì¸ ì—ì´ì „íŠ¸
        self.main_agent = MainAgent(config)
    
    async def run_weekly_analysis(self) -> Dict:
        """ì£¼ê°„ ë¶„ì„ ì‹¤í–‰"""
        
        print("""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘   ğŸ­ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‹œì‘         â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        # 1. ì„œë¸Œ ì—ì´ì „íŠ¸ë“¤ ë³‘ë ¬ ì‹¤í–‰
        print("\n1ï¸âƒ£ ì„œë¸Œ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰...")
        
        tasks = [
            agent.collect_and_analyze() 
            for agent in self.sub_agents
        ]
        
        sub_reports = await asyncio.gather(*tasks)
        
        # 2. ìœ íš¨í•œ ë¦¬í¬íŠ¸ë§Œ í•„í„°ë§
        valid_reports = [r for r in sub_reports if 'error' not in r]
        
        print(f"\nâœ… {len(valid_reports)}/{len(sub_reports)} ì„œë¸Œ ì—ì´ì „íŠ¸ ì„±ê³µ")
        
        # 3. ê³¼ê±° ë°ì´í„°ì™€ ë¹„êµ
        print("\n2ï¸âƒ£ ê³¼ê±° ë°ì´í„° ë¹„êµ ë¶„ì„...")
        context = await self.main_agent.analyze_historical_context(valid_reports)
        
        # 4. ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        print("\n3ï¸âƒ£ ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±...")
        final_report = await self.main_agent.synthesize_final_report(
            valid_reports,
            context
        )
        
        print("""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘   âœ… ë©€í‹° ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ!         â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        return final_report